{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T23:10:00.886294Z",
     "start_time": "2021-09-19T23:10:00.342054Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "from python_utilities.parallel import Parallelizer\n",
    "from e3fp.config.params import default_params\n",
    "from e3fp.pipeline import params_to_dicts\n",
    "from e3fp.pipeline import fprints_from_smiles\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T23:10:00.919548Z",
     "start_time": "2021-09-19T23:10:00.899863Z"
    }
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def multiple_labels(df, col_name):\n",
    "    df[col_name] = df[col_name].str.split(', ')\n",
    "    df = df.explode(col_name, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def class_balanced_split(X, Y, n_classes, train_split=0.8, val_split=None, numsplits=5):\n",
    "    def divide(lst, n):\n",
    "        p = len(lst) // n\n",
    "        if len(lst)-p > 0:\n",
    "            return [lst[:p]] + divide(lst[p:], n-1)\n",
    "        else:\n",
    "            return [lst]\n",
    "    def seed():\n",
    "        return 0.42\n",
    "\n",
    "    n_classes = list(Y)[0].shape[0]\n",
    "    Xtrains = []\n",
    "    Ytrains = []\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    Xval = []\n",
    "    Yval = []\n",
    "    balanced_dict = {}\n",
    "    \n",
    "    # making train/test/val splits within classes\n",
    "    for i in range(n_classes):\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for x, y in zip(X,Y):\n",
    "            if np.argmax(y) == i:\n",
    "                xlist.append(x)\n",
    "                ylist.append(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(xlist, ylist, train_size=train_split, random_state=0)\n",
    "        if val_split:\n",
    "            val_train_size = round(1-val_split/(1-train_split), 3)\n",
    "            X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=val_train_size, random_state=0)\n",
    "            balanced_dict[i] = (X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "        else:\n",
    "            balanced_dict[i] = (X_train, y_train, X_test, y_test)\n",
    "    # recombining train/test/val\n",
    "    for i in range(n_classes):\n",
    "        Xtrains.extend(balanced_dict[i][0])\n",
    "        Ytrains.extend(balanced_dict[i][1])\n",
    "        Xtest.extend(balanced_dict[i][2])\n",
    "        Ytest.extend(balanced_dict[i][3])\n",
    "        if val_split:\n",
    "            Xval.extend(balanced_dict[i][4])\n",
    "            Yval.extend(balanced_dict[i][5])\n",
    "\n",
    "    # shuffling recombined train/test/val\n",
    "    train = list(zip(Xtrains,Ytrains))\n",
    "    test = list(zip(Xtest,Ytest))\n",
    "    random.shuffle(train, seed)\n",
    "    random.shuffle(test, seed)   \n",
    "    # splitting into numsplits and shuffling \n",
    "    split_train = divide(train, numsplits)\n",
    "    split_test = divide(test, numsplits)\n",
    "    for split in split_train:\n",
    "        random.shuffle(split, seed)\n",
    "    for split in split_test:\n",
    "        random.shuffle(split, seed)\n",
    "    if val_split:\n",
    "        val = list(zip(Xval,Yval))\n",
    "        random.shuffle(val, seed)\n",
    "        split_val = divide(val, numsplits)\n",
    "        for split in split_val:\n",
    "            random.shuffle(split, seed)\n",
    "\n",
    "    # unzipping and making list of lists\n",
    "    Xtrains = []\n",
    "    Ytrains = []\n",
    "    Xtests = []\n",
    "    Ytests = []\n",
    "    for i in range(numsplits):\n",
    "        # you can use zip(*iterable) to unzip split_train[i]\n",
    "        Xtrains.append([train[0] for train in split_train[i]])\n",
    "        Ytrains.append([train[1] for train in split_train[i]])\n",
    "        Xtests.append(np.array([test[0] for test in split_test[i]]))\n",
    "        Ytests.append([test[1] for test in split_test[i]])\n",
    "    if val_split:\n",
    "        Xvals = []\n",
    "        Yvals = []\n",
    "        for i in range(numsplits):\n",
    "            Xvals.append([val[0] for val in split_val[i]])\n",
    "            Yvals.append([val[1] for val in split_val[i]])\n",
    "        return Xtrains, Ytrains, Xtests, Ytests, Xvals, Yvals\n",
    "    return Xtrains, Ytrains, Xtests, Ytests\n",
    "\n",
    "def split_labels(df, col_name):\n",
    "    df = df.copy()\n",
    "    df[col_name] = df[col_name].str.split(', ')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(df[col_name].to_list())\n",
    "    return y, mlb.classes_\n",
    "\n",
    "def generate_chemprop_data(labeled_df, excluded_labels, dir, train_split=0.8, val_split=0.1, holdout_split=0.2):\n",
    "    '''\n",
    "    Class-balanced split of train, test, validation, held out, non-held out, and all .csv files from a dataset\n",
    "    '''\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "    multilabel_multiclass_drugs = labeled_df.copy()\n",
    "    multilabel_multiclass_drugs.replace('DNA','nucleic acid', inplace=True)\n",
    "    multilabel_multiclass_drugs.replace('protein','protein biosynthesis', inplace=True)\n",
    "    mask = [label not in excluded_labels for label in multilabel_multiclass_drugs['labels']]\n",
    "    masked_multilabel_df = multilabel_multiclass_drugs[mask]\n",
    "    Y, classes = split_labels(masked_multilabel_df, 'labels')\n",
    "    classes = [label.replace(' ','_') for label in classes]\n",
    "    X = masked_multilabel_df['canon_SMILES'].to_list()\n",
    "    Xcp, Ycp, Xhold, Yhold = class_balanced_split(X, Y, n_classes=len(classes), train_split=1-holdout_split, numsplits=1)\n",
    "    Xtrains, Ytrains, Xtests, Ytests, Xvals, Yvals = class_balanced_split(Xcp[0], Ycp[0], n_classes=len(classes), train_split=train_split, val_split=val_split, numsplits=1)\n",
    "    \n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "    hold_df = pd.DataFrame()\n",
    "    train_df['smiles'] = Xtrains[0]\n",
    "    test_df['smiles'] = Xtests[0]\n",
    "    val_df['smiles'] = Xvals[0]\n",
    "    hold_df['smiles'] = Xhold[0]\n",
    "    for i in range(len(classes)):\n",
    "        train_df[classes[i]] = np.vstack(Ytrains[0])[:,i]\n",
    "        test_df[classes[i]] = np.vstack(Ytests[0])[:,i]\n",
    "        val_df[classes[i]] = np.vstack(Yvals[0])[:,i]\n",
    "        hold_df[classes[i]] = np.vstack(Yhold[0])[:,i]\n",
    "    print(' '.join(classes))\n",
    "    train_df.to_csv(dir+'train.csv',index=False)\n",
    "    test_df.to_csv(dir+'test.csv',index=False)\n",
    "    val_df.to_csv(dir+'val.csv',index=False)\n",
    "    hold_df.to_csv(dir+'holdout.csv',index=False)\n",
    "    hold_df['smiles'].to_csv(dir+'holdout_smiles_only.csv',index=False)\n",
    "    all_df = pd.concat([train_df,test_df,val_df,hold_df])\n",
    "    all_df.to_csv(dir+'all.csv',index=False)\n",
    "    nonholdout_df = pd.concat([train_df,test_df,val_df])\n",
    "    nonholdout_df.to_csv(dir+'nonholdout.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T23:10:01.276120Z",
     "start_time": "2021-09-19T23:10:01.236299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial length: 2857\n",
      "filtered for SMILES: 2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-6d7b2dcfc4ac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].str.split(', ')\n"
     ]
    }
   ],
   "source": [
    "# get morgan fingerprints for all\n",
    "data_dir = '../data/'\n",
    "file_name = 'abx_MOA_fully_relabeled_v2.csv'\n",
    "file_path = data_dir+file_name\n",
    "\n",
    "drugs = pd.read_csv(file_path)\n",
    "print('initial length:',len(drugs))\n",
    "not_nans = [type(smi) != float for smi in list(drugs['canon_SMILES'])]\n",
    "drugs = drugs[not_nans] # filter for having SMILE\n",
    "print('filtered for SMILES:',len(drugs))\n",
    "\n",
    "# multilabel multiclass\n",
    "labeled = [moa != 'unknown' for moa in drugs['labels']]\n",
    "labeled_drugs = drugs[labeled] # filter labeled drugs i.e. not unknown\n",
    "multilabel_multiclass_drugs = labeled_drugs.copy()\n",
    "multilabel_multiclass_drugs.replace('DNA','nucleic acid', inplace=True)\n",
    "multilabel_multiclass_drugs.replace('protein','protein biosynthesis', inplace=True)\n",
    "# single label multiclass\n",
    "labeled_drugs = multiple_labels(labeled_drugs,'labels') # dealing with multiple MOA\n",
    "labeled_drugs.replace('DNA','nucleic acid', inplace=True)\n",
    "labeled_drugs.replace('protein','protein biosynthesis', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T23:10:01.749577Z",
     "start_time": "2021-09-19T23:10:01.608310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoA_synthesis PMF cell_division cell_wall membrane nucleic_acid oxidative_stress protein_biosynthesis\n"
     ]
    }
   ],
   "source": [
    "# generating chemprop train, test, val, non-held out (used for hyperparameter optimization),\n",
    "# held out (used for test set when hyperparamter optimizing) .csv files\n",
    "dir = '../data/chemprop_nonhuman_multilabel_inputs/'\n",
    "excluded_labels = ['human']\n",
    "generate_chemprop_data(multilabel_multiclass_drugs,excluded_labels,dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Generating E3FPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T23:10:02.686995Z",
     "start_time": "2021-09-19T23:10:02.674548Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading smiles, parameters\n",
    "dir = '../data/chemprop_nonhuman_multilabel_inputs/'\n",
    "test_df = pd.read_csv(dir+'all.csv')\n",
    "smiles = test_df['smiles'].to_list()\n",
    "\n",
    "confgen_params, fprint_params = params_to_dicts(default_params)\n",
    "confgen_params = {'num_conf': -1, 'first': -1, 'pool_multiplier': 1, 'rmsd_cutoff': 0.5, 'max_energy_diff': None, 'forcefield': 'uff', 'out_dir': 'conformers', 'compress': 2, 'seed': -1, 'standardise': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:41:40.593327Z",
     "start_time": "2021-09-20T13:34:53.024Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating conformers in parallel\n",
    "smiles_dict = {str(i): smiles[i] for i in range(len(smiles))}\n",
    "smiles_iter = ((smiles, name) for name, smiles in smiles_dict.items())\n",
    "kwargs = {\"confgen_params\": confgen_params, \"fprint_params\": fprint_params}\n",
    "parallelizer = Parallelizer(parallel_mode=\"processes\")\n",
    "%time fprints_list = parallelizer.run(fprints_from_smiles, smiles_iter, kwargs=kwargs) \n",
    "len(fprints_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:41:40.586797Z",
     "start_time": "2021-09-19T23:10:05.742Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fprints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:41:40.589928Z",
     "start_time": "2021-09-20T06:09:08.657Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import pickle\n",
    "filehandler = open('../data/training_e3fps', 'w') \n",
    "pickle.dump(fprints_list, filehandler)\n",
    "dump(fprints_list,'../data/training_e3fps.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ae21d304a232f70e152a751ed602b44bcd727620c22ca963b1923550a9bd32b"
  },
  "kernelspec": {
   "display_name": "abx_moa",
   "language": "python",
   "name": "abx_moa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 335.79999999999995,
   "position": {
    "height": "40px",
    "left": "1126px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
